{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset,ConcatDataset\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NimbroDataset(Dataset):\n",
    "    def __init__(self,image_dir,image_size,object_to_channel = {'ball':0,'goalpost':2,'robot':1},object_var = {'ball':5,'goalpost':5,'robot':10}\n",
    "):\n",
    "        # List of all xml files\n",
    "        self.xml_files = glob.glob(image_dir+'/*.xml')\n",
    "\n",
    "        # channel for each object\n",
    "        self.object_to_channel = object_to_channel\n",
    "        \n",
    "        # variance for each object (higher for robot)\n",
    "        self.object_var = object_var\n",
    "        \n",
    "        # for resizing and normalising\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "        self.resize_inp = transforms.Compose([transforms.ToPILImage(),transforms.Resize(image_size),transforms.ToTensor()])        \n",
    "        \n",
    "        # for caching target and input image path\n",
    "        self.data = [ i for i in range(len(self.xml_files))]\n",
    "\n",
    "        self.image_size = image_size\n",
    "            \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        f = self.xml_files[index]\n",
    "        \n",
    "        # if annotated target and input image is saved in the cache\n",
    "        if type(self.data[index]) != int:\n",
    "            img_path,target = self.data[index]\n",
    "        else:   \n",
    "            img_path,annot = self.parse_annotations(f)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(f.replace('xml',img_path.split('.')[-1]))\n",
    "\n",
    "        except:\n",
    "            image = Image.open('/'.join(f.split('/')[:-1] + [img_path.split('/')[-1]]))\n",
    "        \n",
    "        \n",
    "        x = TF.to_tensor(image)\n",
    "\n",
    "        #  if target not saved in the cache\n",
    "        if type(self.data[index]) == int:\n",
    "            # generating target\n",
    "            target = self.annotation_to_target(annot,x.shape[1],x.shape[2])\n",
    "            # saving target in cache\n",
    "            self.data[index] = (img_path,target)\n",
    "            \n",
    "        \n",
    "        x = self.resize_inp(x)\n",
    "        x = self.normalize(x)\n",
    "        \n",
    "        return x,target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.xml_files)\n",
    "                           \n",
    "    def parse_annotations(self, fname):\n",
    "        '''\n",
    "        method for parsing xml file to get annotations and path\n",
    "        '''\n",
    "        tree = ET.parse(fname)\n",
    "        dpoints = {'ball': np.array([]), 'goalpost': np.array([]), 'robot': np.array([])}\n",
    "        image_path = ''\n",
    "        for elems in tree.iter():\n",
    "            if elems.tag == \"path\" or elems.tag == \"filename\":\n",
    "                if len(image_path) < len(elems.text):\n",
    "                    image_path = elems.text\n",
    "                    \n",
    "            if elems.tag == \"object\":\n",
    "                for elem in elems:\n",
    "                    if elem.tag == \"name\":\n",
    "                        label = str(elem.text)              \n",
    "                    if elem.tag == \"bndbox\":\n",
    "                        i=0\n",
    "                        bbox_coords = {}\n",
    "                        for k in elem:\n",
    "                            bbox_coords[i] = float(k.text)\n",
    "                            i = i+1\n",
    "                \n",
    "                # calculating bottom center for goalposts\n",
    "                if label == 'goalpost':\n",
    "                        mid_x_y = [(bbox_coords[0] + bbox_coords[2]) / 2, bbox_coords[3]]\n",
    "                    \n",
    "                # for ball and robot, it is a normal center\n",
    "                else:\n",
    "                    mid_x_y = [(bbox_coords[0] + bbox_coords[2]) / 2, (bbox_coords[1] + bbox_coords[3]) / 2]\n",
    "                dpoints[label] = np.append(dpoints[label], mid_x_y[::-1], axis=0)\n",
    "        for k in dpoints.keys():\n",
    "            dpoints[k] = dpoints[k].reshape((-1, 2))\n",
    "        return image_path,dpoints\n",
    "        \n",
    "                           \n",
    "    def annotation_to_target(self,annot,h,w):\n",
    "        '''\n",
    "        method to generate target image from annotations\n",
    "        '''\n",
    "        # creating empty target of one fourth of input image size\n",
    "        h_,w_ = self.image_size[0]//4,self.image_size[1]//4\n",
    "        target = np.zeros((len(self.object_to_channel),h_,w_), dtype='float32')\n",
    "        \n",
    "        # all coordinates for target pixels to calculate gaussian\n",
    "        y = np.linspace(0,h_ - 1,num=h_)\n",
    "        x = np.linspace(0,w_- 1,num=w_)\n",
    "        xx,yy = np.meshgrid(x,y)\n",
    "        z = zip(yy.reshape(-1),xx.reshape(-1))\n",
    "        coords = [coord for coord in z]\n",
    "        \n",
    "        # iterating over objects (Ball, Goal posts, Robot)\n",
    "        for object_ in annot.keys():\n",
    "            # iterating over each center\n",
    "            for coord in annot[object_]:\n",
    "                variance = self.object_var[object_]\n",
    "                \n",
    "                #normalising center according to original size\n",
    "                mean = [coord[0]*h_/h,coord[1]*w_/w]\n",
    "                \n",
    "                # creating gaussian with given center and variance\n",
    "                rv = multivariate_normal(mean, [[variance, 0], [0, variance]])\n",
    "                \n",
    "                # adding values of blobs from target with proper scaling\n",
    "                target[self.object_to_channel[object_],:,:] += variance*rv.pdf(coords).reshape(h_,w_)\n",
    "        \n",
    "        target = torch.from_numpy(target)\n",
    "        \n",
    "        # for scaling values approx between 1 and 0\n",
    "        target[0,:,:] /= target[0,:,:].max() + 0.00000001\n",
    "        target[1,:,:] /= target[1,:,:].max() + 0.00000001\n",
    "        target[2,:,:] /= target[2,:,:].max() + 0.00000001\n",
    "        return target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
