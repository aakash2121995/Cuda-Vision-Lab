{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fab8c05d0f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms,datasets\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10(root = './data',transform=transforms.ToTensor(),download=True)\n",
    "test_data  = datasets.CIFAR10(root = './data',train=False,transform=transforms.ToTensor(),download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "EPOCHS = 500\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,BATCH_SIZE,True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,inp_channels=3,input_size=32,output_size=10):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=inp_channels,out_channels=64,kernel_size=3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "                \n",
    "        # Maxpool1\n",
    "#         self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Convolution 3\n",
    "        self.cnn3 = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # Maxpool 1\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "                \n",
    "        # Convolution 4\n",
    "        self.cnn4 = nn.Conv2d(in_channels=32,out_channels=32,kernel_size=3)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.cnn4_drop = nn.Dropout2d(0.2)\n",
    "        \n",
    "        # Convolution 5\n",
    "        self.cnn5 = nn.Conv2d(in_channels=32,out_channels=16,kernel_size=3)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        \n",
    "        # Fully Connected 1\n",
    "        self.fc1 = nn.Linear(16*9*9,output_size)\n",
    "#         self.relu6 = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(128,output_size)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x = 100,3,32,32\n",
    "        \n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x) # out = 100,64,30,30\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        # Convolution 2\n",
    "        out = self.cnn2(out) # out = 100,64,28,28\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        out = self.cnn3(out) # out = 100,32,26,26\n",
    "        out = self.relu3(out)\n",
    "        out = self.maxpool3(out) # out = 100,32,13,13\n",
    "        \n",
    "        out = self.cnn4(out) # out = 100,32,11,11\n",
    "        out = self.relu4(out)\n",
    "        \n",
    "        out = self.cnn5(out) # out = 100,16,9,9\n",
    "        out = self.relu5(out)\n",
    "        \n",
    "        out = out.view(out.size(0),-1)\n",
    "        \n",
    "        # Fully Connected layer 1\n",
    "        out = self.fc1(out)\n",
    "#         out = self.relu6(out)\n",
    "#         out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "learning_rate = 0.06\n",
    " \n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_save = torch.zeros(int(EPOCHS*len(train_data)/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(loader,model):\n",
    "    # Calculate Accuracy         \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Iterate through test dataset\n",
    "    for images, labels in loader:\n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "\n",
    "        # Forward pass only to get logits/output\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Get predictions from the maximum value\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Total number of labels\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Total correct predictions\n",
    "        correct += (predicted.cpu() == labels.cpu()).sum().float()\n",
    "\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000. Loss: 1.684850811958313, Test Accuracy: 37.5099983215332,Train Accuracy: 37.762001037597656\n",
      "Iteration: 2000. Loss: 1.4713906049728394, Test Accuracy: 46.16999816894531,Train Accuracy: 45.832000732421875\n",
      "Iteration: 3000. Loss: 1.417387843132019, Test Accuracy: 52.40999984741211,Train Accuracy: 53.38399887084961\n",
      "Iteration: 4000. Loss: 1.3616889715194702, Test Accuracy: 54.529998779296875,Train Accuracy: 55.263999938964844\n",
      "Iteration: 5000. Loss: 1.1882046461105347, Test Accuracy: 57.779998779296875,Train Accuracy: 59.61600112915039\n",
      "Iteration: 6000. Loss: 1.0920581817626953, Test Accuracy: 59.2400016784668,Train Accuracy: 61.18000030517578\n",
      "Iteration: 7000. Loss: 1.154478669166565, Test Accuracy: 60.970001220703125,Train Accuracy: 63.02399826049805\n",
      "Iteration: 8000. Loss: 0.9769262671470642, Test Accuracy: 61.75,Train Accuracy: 64.28199768066406\n",
      "Iteration: 9000. Loss: 1.0445170402526855, Test Accuracy: 63.029998779296875,Train Accuracy: 65.6520004272461\n",
      "Iteration: 10000. Loss: 1.0447044372558594, Test Accuracy: 64.58999633789062,Train Accuracy: 66.81999969482422\n",
      "Iteration: 11000. Loss: 0.9057950377464294, Test Accuracy: 66.5199966430664,Train Accuracy: 69.12000274658203\n",
      "Iteration: 14000. Loss: 0.8804810643196106, Test Accuracy: 68.01000213623047,Train Accuracy: 71.04000091552734\n",
      "Iteration: 15000. Loss: 0.8539043068885803, Test Accuracy: 69.05999755859375,Train Accuracy: 72.53199768066406\n",
      "Iteration: 16000. Loss: 0.708649754524231, Test Accuracy: 70.2300033569336,Train Accuracy: 73.5979995727539\n",
      "Iteration: 17000. Loss: 0.7306500673294067, Test Accuracy: 70.76000213623047,Train Accuracy: 74.43800354003906\n",
      "Iteration: 18000. Loss: 0.7374936938285828, Test Accuracy: 70.0199966430664,Train Accuracy: 73.45600128173828\n",
      "Iteration: 19000. Loss: 0.7130630612373352, Test Accuracy: 71.8499984741211,Train Accuracy: 75.66999816894531\n",
      "Iteration: 20000. Loss: 0.6755303144454956, Test Accuracy: 71.20999908447266,Train Accuracy: 75.69200134277344\n",
      "Iteration: 21000. Loss: 0.6253769397735596, Test Accuracy: 72.23999786376953,Train Accuracy: 76.71199798583984\n",
      "Iteration: 22000. Loss: 0.6517654657363892, Test Accuracy: 72.61000061035156,Train Accuracy: 77.18599700927734\n",
      "Iteration: 23000. Loss: 0.7056501507759094, Test Accuracy: 71.66999816894531,Train Accuracy: 76.70800018310547\n",
      "Iteration: 24000. Loss: 0.6484329700469971, Test Accuracy: 71.76000213623047,Train Accuracy: 77.06199645996094\n",
      "Iteration: 25000. Loss: 0.705242395401001, Test Accuracy: 72.4800033569336,Train Accuracy: 77.55999755859375\n",
      "Iteration: 26000. Loss: 0.6963217258453369, Test Accuracy: 72.22000122070312,Train Accuracy: 78.0199966430664\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "         \n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "         \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "         \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_save[iter] = loss.item()\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "         \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "         \n",
    "        iter += 1\n",
    "         \n",
    "        if iter % 1000 == 0:\n",
    "            # Print Loss\n",
    "            test_accuracy = accuracy(test_loader,model)\n",
    "            train_accuracy = accuracy(train_loader,model)\n",
    "            print('Iteration: {}. Loss: {}, Test Accuracy: {},Train Accuracy: {}'.format(iter, loss.item(), test_accuracy,train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_save.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "ax = sns.lineplot(data = loss_save.numpy())\n",
    "ax.set(xlabel = \"Iterations\", ylabel=\"Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
