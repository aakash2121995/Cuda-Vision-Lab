{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc2580350f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms,datasets\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10(root = './data',transform=transforms.ToTensor(),download=True)\n",
    "test_data  = datasets.CIFAR10(root = './data',train=False,transform=transforms.ToTensor(),download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "EPOCHS = 800\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,BATCH_SIZE,True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,inp_channels=3,input_size=32,output_size=10):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=inp_channels,out_channels=64,kernel_size=3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "                \n",
    "        # Maxpool1\n",
    "#         self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Convolution 3\n",
    "        self.cnn3 = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # Maxpool 1\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "                \n",
    "        # Convolution 4\n",
    "        self.cnn4 = nn.Conv2d(in_channels=32,out_channels=32,kernel_size=3)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.cnn4_drop = nn.Dropout2d(0.2)\n",
    "        \n",
    "        # Convolution 5\n",
    "        self.cnn5 = nn.Conv2d(in_channels=32,out_channels=16,kernel_size=3)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        \n",
    "        self.cnn6 = nn.Conv2d(in_channels=16,out_channels=16,kernel_size=3)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        \n",
    "        # Fully Connected 1\n",
    "        self.fc1 = nn.Linear(16*7*7,output_size)\n",
    "#         self.relu6 = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(128,output_size)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x = 100,3,32,32\n",
    "        \n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x) # out = 100,64,30,30\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        # Convolution 2\n",
    "        out = self.cnn2(out) # out = 100,64,28,28\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        out = self.cnn3(out) # out = 100,32,26,26\n",
    "        out = self.relu3(out)\n",
    "        out = self.maxpool3(out) # out = 100,32,13,13\n",
    "        \n",
    "        out = self.cnn4(out) # out = 100,32,11,11\n",
    "        out = self.relu4(out)\n",
    "        \n",
    "        out = self.cnn5(out) # out = 100,16,9,9\n",
    "        out = self.relu5(out)\n",
    "        \n",
    "        out = self.cnn6(out) # out = 100,16,7,7\n",
    "        out = self.relu6(out)\n",
    "        \n",
    "        out = out.view(out.size(0),-1)\n",
    "        \n",
    "        # Fully Connected layer 1\n",
    "        out = self.fc1(out)\n",
    "#         out = self.relu6(out)\n",
    "#         out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "learning_rate = 0.05\n",
    " \n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate,rho=0.95,weight_decay=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss_save = torch.zeros(int(EPOCHS*len(train_data)/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(loader,model):\n",
    "    # Calculate Accuracy         \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Iterate through test dataset\n",
    "    for images, labels in loader:\n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "\n",
    "        # Forward pass only to get logits/output\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Get predictions from the maximum value\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Total number of labels\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Total correct predictions\n",
    "        correct += (predicted.cpu() == labels.cpu()).sum().float()\n",
    "\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "%%time\n",
    "iter = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "         \n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "         \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "         \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_save[iter] = loss.item()\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "         \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "         \n",
    "        iter += 1\n",
    "         \n",
    "        if iter % 1000 == 0:\n",
    "            # Print Loss\n",
    "            test_accuracy = accuracy(test_loader,model)\n",
    "            train_accuracy = accuracy(train_loader,model)\n",
    "            print('Iteration: {}. Loss: {}, Test Accuracy: {},Train Accuracy: {}'.format(iter, loss.item(), test_accuracy,train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "TOTAL_PARAMS = 20\n",
    "param_loss = np.zeros((TOTAL_PARAMS))\n",
    "param_test_accuracy = np.zeros((TOTAL_PARAMS))\n",
    "param_train_accyracy = np.zeros((TOTAL_PARAMS))\n",
    "# selecting learning rate between 0.005 and 0.5\n",
    "r = -2*np.random.random_sample((TOTAL_PARAMS)) - 1\n",
    "learning_rate = np.power(10,r)*5\n",
    "\n",
    "# selecting momentum between 1 - 0.001 and 1 - 0.1\n",
    "r = -2*np.random.random_sample((TOTAL_PARAMS)) - 1\n",
    "momentum = 1 - np.power(10,r)\n",
    "\n",
    "# selecting weight decay between 0.001 and 0.01\n",
    "r = np.random.random_sample((TOTAL_PARAMS)) - 3\n",
    "decay = np.power(10,r)\n",
    "\n",
    "for param_iter in range(TOTAL_PARAMS):\n",
    "    model = CNN()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    \n",
    "    optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate[param_iter],rho=momentum[param_iter],weight_decay=decay[param_iter])\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss_save = torch.zeros(int(EPOCHS*len(train_data)/BATCH_SIZE))\n",
    "    \n",
    "    iter = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            #######################\n",
    "            #  USE GPU FOR MODEL  #\n",
    "            #######################\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "\n",
    "            # Clear gradients w.r.t. parameters\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass to get output/logits\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Calculate Loss: softmax --> cross entropy loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_save[iter] = loss.item()\n",
    "\n",
    "            # Getting gradients w.r.t. parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # Updating parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            iter +=1\n",
    "            if iter % 1000 == 0:\n",
    "                # Print Loss\n",
    "                test_accuracy = accuracy(test_loader,model)\n",
    "                train_accuracy = accuracy(train_loader,model)\n",
    "                print('Iteration: {}. Loss: {}, Test Accuracy: {},Train Accuracy: {}'.format(iter, loss.item(), test_accuracy,train_accuracy))\n",
    "    \n",
    "    \n",
    "    test_accuracy = accuracy(test_loader,model)\n",
    "    train_accuracy = accuracy(train_loader,model)\n",
    "    print('Learning Rate:{}, Momentum:{}, Weight decay:{}'.format(learning_rate[param_iter],momentum[param_iter],decay[param_iter]))\n",
    "    print('Loss: {}, Test Accuracy: {},Train Accuracy: {}'.format(loss.item(), test_accuracy,train_accuracy))\n",
    "                            \n",
    "    ax = sns.lineplot(data = loss_save.numpy())\n",
    "    ax.set(xlabel = \"Iterations\", ylabel=\"Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "with open('output.txt', 'w') as out:\n",
    "   out.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cap.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = sns.lineplot(data = loss_save.numpy())\n",
    "ax.set(xlabel = \"Iterations\", ylabel=\"Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
