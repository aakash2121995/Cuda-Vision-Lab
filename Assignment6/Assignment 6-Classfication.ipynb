{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn,utils\n",
    "from torchvision import datasets,transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "epoch = 50\n",
    "batch_size = 100\n",
    "\n",
    "train = datasets.CIFAR10('./',train=True,transform=transforms.ToTensor(),target_transform=None,download=True)\n",
    "test  = datasets.CIFAR10('./',train=False,transform=transforms.ToTensor(),target_transform=None,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iters = int(epoch*len(train)/batch_size)\n",
    "n_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = utils.data.DataLoader(train,batch_size=batch_size,shuffle=True)\n",
    "test_loader = utils.data.DataLoader(test,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3,16,3,padding=1), # batch X 16 X 32 X 32\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16,32,3,padding=1), # batch X 32 X 32 X 32\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32,32,3,padding=1), # batch X 32 X 32 X 32\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32,64,3,padding=1), # batch X 64 X 32 X 32\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64,64,3,padding=1), # batch X 64 X 32 X 32\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.MaxPool2d(2,2)            # batch X 64 X 16 X 16\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64,128,3,padding=1), # batch X 128 X 16 X 16\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128,128,3,padding=1), # batch X 128 X 16 X 16\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128,256,3,padding=1), # batch X 256 X 16 X 16\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2,2),              # batch X 256 X 8 X 8\n",
    "            nn.Conv2d(256,256,3,padding=1), # batch X 256 X 8 X 8\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(batch_size,-1)\n",
    "        return out\n",
    "        \n",
    "encoder = Encoder().cuda()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256,256,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ConvTranspose2d(256,128,3,2,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ConvTranspose2d(128,128,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ConvTranspose2d(128,64,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64,64,3,2,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ConvTranspose2d(64,32,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ConvTranspose2d(32,32,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ConvTranspose2d(32,16,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ConvTranspose2d(16,3,3,1,1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = x.view(batch_size,256,8,8)\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        return out\n",
    "decoder = Decoder().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classification,self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256*8*8,40),\n",
    "#             nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(40, 10)\n",
    "            nn.ReLU()\n",
    "#            \n",
    "        )\n",
    "    def forward(self,x):\n",
    "        out = self.classifier(x)\n",
    "        return out\n",
    "    \n",
    "classifier = Classification().cuda()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "for image,label in loader:\n",
    "    image = image.cuda()\n",
    "    \n",
    "    output = encoder(image)\n",
    "    output = classifier(output)\n",
    "    print(output.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "# lr = 0.001\n",
    "loss_fn = nn.CrossEntropyLoss().cuda()\n",
    "# loss_fn = nn.Softmax()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(),lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------model restored--------\n",
      "\n",
      "Iteration: 1000. Loss: 1.1496120691299438. Test Accuracy: 50.08000183105469\n",
      "Iteration: 1000. Train Accuracy: 52.97800064086914\n",
      "Iteration: 2000. Loss: 1.3710001707077026. Test Accuracy: 53.290000915527344\n",
      "Iteration: 2000. Train Accuracy: 56.7400016784668\n",
      "Iteration: 3000. Loss: 1.245559811592102. Test Accuracy: 54.59000015258789\n",
      "Iteration: 3000. Train Accuracy: 59.36399841308594\n",
      "Iteration: 4000. Loss: 1.1629688739776611. Test Accuracy: 55.619998931884766\n",
      "Iteration: 4000. Train Accuracy: 61.492000579833984\n",
      "Iteration: 5000. Loss: 1.183366298675537. Test Accuracy: 56.119998931884766\n",
      "Iteration: 5000. Train Accuracy: 61.5260009765625\n",
      "Iteration: 6000. Loss: 1.0649107694625854. Test Accuracy: 57.650001525878906\n",
      "Iteration: 6000. Train Accuracy: 64.00199890136719\n",
      "Iteration: 7000. Loss: 1.0474884510040283. Test Accuracy: 56.099998474121094\n",
      "Iteration: 7000. Train Accuracy: 62.84400177001953\n",
      "Iteration: 8000. Loss: 0.9474456310272217. Test Accuracy: 57.790000915527344\n",
      "Iteration: 8000. Train Accuracy: 64.8740005493164\n",
      "Iteration: 9000. Loss: 1.195632815361023. Test Accuracy: 58.5\n",
      "Iteration: 9000. Train Accuracy: 66.30599975585938\n",
      "Iteration: 10000. Loss: 1.0162537097930908. Test Accuracy: 57.529998779296875\n",
      "Iteration: 10000. Train Accuracy: 65.48200225830078\n",
      "Iteration: 11000. Loss: 1.1051441431045532. Test Accuracy: 57.189998626708984\n",
      "Iteration: 11000. Train Accuracy: 65.08399963378906\n",
      "Iteration: 12000. Loss: 1.1011625528335571. Test Accuracy: 58.970001220703125\n",
      "Iteration: 12000. Train Accuracy: 67.81199645996094\n",
      "Iteration: 13000. Loss: 0.8224878907203674. Test Accuracy: 58.349998474121094\n",
      "Iteration: 13000. Train Accuracy: 68.95600128173828\n",
      "Iteration: 14000. Loss: 1.1562656164169312. Test Accuracy: 57.349998474121094\n",
      "Iteration: 14000. Train Accuracy: 67.11199951171875\n",
      "Iteration: 15000. Loss: 0.8979167938232422. Test Accuracy: 60.0099983215332\n",
      "Iteration: 15000. Train Accuracy: 70.54399871826172\n",
      "Iteration: 16000. Loss: 0.8344968557357788. Test Accuracy: 58.4900016784668\n",
      "Iteration: 16000. Train Accuracy: 69.2699966430664\n",
      "Iteration: 17000. Loss: 0.8967469930648804. Test Accuracy: 59.939998626708984\n",
      "Iteration: 17000. Train Accuracy: 71.01599884033203\n",
      "Iteration: 18000. Loss: 0.79731285572052. Test Accuracy: 58.54999923706055\n",
      "Iteration: 18000. Train Accuracy: 70.16999816894531\n",
      "Iteration: 19000. Loss: 1.0119436979293823. Test Accuracy: 58.630001068115234\n",
      "Iteration: 19000. Train Accuracy: 70.73400115966797\n",
      "Iteration: 20000. Loss: 0.8296962976455688. Test Accuracy: 58.400001525878906\n",
      "Iteration: 20000. Train Accuracy: 70.66600036621094\n",
      "Iteration: 21000. Loss: 0.7023143768310547. Test Accuracy: 59.43000030517578\n",
      "Iteration: 21000. Train Accuracy: 72.37200164794922\n",
      "Iteration: 22000. Loss: 1.0000661611557007. Test Accuracy: 57.13999938964844\n",
      "Iteration: 22000. Train Accuracy: 69.46800231933594\n",
      "Iteration: 23000. Loss: 0.9032447338104248. Test Accuracy: 59.59000015258789\n",
      "Iteration: 23000. Train Accuracy: 71.68399810791016\n",
      "Iteration: 24000. Loss: 0.7259343862533569. Test Accuracy: 58.11000061035156\n",
      "Iteration: 24000. Train Accuracy: 70.18800354003906\n",
      "Iteration: 25000. Loss: 0.9480639100074768. Test Accuracy: 59.20000076293945\n",
      "Iteration: 25000. Train Accuracy: 72.66000366210938\n",
      "tensor(0.9481, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./classification_model'):\n",
    "    os.mkdir('./classification_model')\n",
    "try:\n",
    "    encoder, _ = torch.load('./model/deno_autoencoder.pkl')\n",
    "    print(\"\\n--------model restored--------\\n\")\n",
    "except:\n",
    "    print(\"\\n--------model not restored--------\\n\")\n",
    "    pass\n",
    "\n",
    "loss_save = np.empty(n_iters-1)\n",
    "\n",
    "iter = 0\n",
    "\n",
    "for i in range(epoch):\n",
    "    for image,label in loader:\n",
    "#         image_n = torch.mul(image+0.25, 0.1 * torch.rand(batch_size,3,32,32))\n",
    "        image = image.cuda()\n",
    "#         image_n = image_n.cuda()\n",
    "        label = label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = encoder(image)\n",
    "        output = classifier(output)\n",
    "        loss = loss_fn(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #Save Loss    \n",
    "        \n",
    "        loss_save[iter-1] = loss.item()\n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 1000 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for image, labels in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                image = image.cuda()\n",
    "                 \n",
    "                # Forward pass only to get logits/output\n",
    "                output = encoder(image)\n",
    "                output = classifier(output)\n",
    "                 \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                 \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                 \n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum().float()\n",
    "             \n",
    "            accuracy = 100. * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Test Accuracy: {}'.format(iter, loss.item(), accuracy))\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for image, labels in loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                image = image.cuda()\n",
    "                 \n",
    "                # Forward pass only to get logits/output\n",
    "                output = encoder(image)\n",
    "                output = classifier(output)\n",
    "                 \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                 \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                 \n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum().float()\n",
    "             \n",
    "            accuracy = 100. * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Train Accuracy: {}'.format(iter, accuracy))\n",
    "        \n",
    "                \n",
    "# torch.save([encoder,decoder],'./model/deno_autoencoder.pkl')\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
