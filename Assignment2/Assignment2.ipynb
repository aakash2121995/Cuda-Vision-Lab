{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import random as rand\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = dsets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testset = dsets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    avDev = torch.device(\"cuda\")\n",
    "else:\n",
    "    avDev = torch.device(\"cpu\")\n",
    "\n",
    "print(avDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6039, 0.4941, 0.4118,  ..., 0.3569, 0.3412, 0.3098],\n",
       "         [0.5490, 0.5686, 0.4902,  ..., 0.3765, 0.3020, 0.2784],\n",
       "         [0.5490, 0.5451, 0.4510,  ..., 0.3098, 0.2667, 0.2627],\n",
       "         ...,\n",
       "         [0.6863, 0.6118, 0.6039,  ..., 0.1647, 0.2392, 0.3647],\n",
       "         [0.6471, 0.6118, 0.6235,  ..., 0.4039, 0.4824, 0.5137],\n",
       "         [0.6392, 0.6196, 0.6392,  ..., 0.5608, 0.5608, 0.5608]],\n",
       "\n",
       "        [[0.6941, 0.5373, 0.4078,  ..., 0.3725, 0.3529, 0.3176],\n",
       "         [0.6275, 0.6000, 0.4902,  ..., 0.3882, 0.3137, 0.2863],\n",
       "         [0.6078, 0.5725, 0.4510,  ..., 0.3216, 0.2745, 0.2706],\n",
       "         ...,\n",
       "         [0.6549, 0.6039, 0.6275,  ..., 0.1333, 0.2078, 0.3255],\n",
       "         [0.6039, 0.5961, 0.6314,  ..., 0.3647, 0.4471, 0.4745],\n",
       "         [0.5804, 0.5804, 0.6118,  ..., 0.5216, 0.5255, 0.5216]],\n",
       "\n",
       "        [[0.7333, 0.5333, 0.3725,  ..., 0.2784, 0.2784, 0.2745],\n",
       "         [0.6627, 0.6039, 0.4627,  ..., 0.3059, 0.2431, 0.2392],\n",
       "         [0.6431, 0.5843, 0.4392,  ..., 0.2510, 0.2157, 0.2157],\n",
       "         ...,\n",
       "         [0.6510, 0.6275, 0.6667,  ..., 0.1412, 0.2235, 0.3569],\n",
       "         [0.5020, 0.5098, 0.5569,  ..., 0.3765, 0.4706, 0.5137],\n",
       "         [0.4706, 0.4784, 0.5216,  ..., 0.5451, 0.5569, 0.5647]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: MAKING DATASET ITERABLE\n",
    " \n",
    "batch_size = 100\n",
    "n_iters = 8000\n",
    "num_epochs = n_iters / (len(trainset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    " \n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    " \n",
    "test_loader = torch.utils.data.DataLoader(dataset=testset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 3000)\n",
    "        self.linear2 = nn.Linear(3000, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "     \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.linear1(x))\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 3*32*32\n",
    "output_dim = 10\n",
    " \n",
    "model = LogisticRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    " \n",
    "model.to(avDev)\n",
    " \n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss().to(avDev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.05\n",
    " \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.6950961351394653. Accuracy: 37.0\n",
      "Iteration: 1000. Loss: 1.7218607664108276. Accuracy: 42.77000045776367\n",
      "Iteration: 1500. Loss: 1.6938046216964722. Accuracy: 44.56999969482422\n",
      "Iteration: 2000. Loss: 1.350484013557434. Accuracy: 44.599998474121094\n",
      "Iteration: 2500. Loss: 1.672101616859436. Accuracy: 46.279998779296875\n",
      "Iteration: 3000. Loss: 1.3435059785842896. Accuracy: 46.439998626708984\n",
      "Iteration: 3500. Loss: 1.4951679706573486. Accuracy: 47.18000030517578\n",
      "Iteration: 4000. Loss: 1.5503381490707397. Accuracy: 43.689998626708984\n",
      "Iteration: 4500. Loss: 1.3230040073394775. Accuracy: 48.2400016784668\n",
      "Iteration: 5000. Loss: 1.484330177307129. Accuracy: 49.2599983215332\n",
      "Iteration: 5500. Loss: 1.5285321474075317. Accuracy: 51.060001373291016\n",
      "Iteration: 6000. Loss: 1.4910595417022705. Accuracy: 49.81999969482422\n",
      "Iteration: 6500. Loss: 1.1991504430770874. Accuracy: 51.13999938964844\n",
      "Iteration: 7000. Loss: 1.3498021364212036. Accuracy: 47.33000183105469\n",
      "Iteration: 7500. Loss: 1.3073405027389526. Accuracy: 49.27000045776367\n",
      "Iteration: 8000. Loss: 1.3764393329620361. Accuracy: 49.09000015258789\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "         \n",
    "        images = images.view(-1, 3*32*32).to(avDev)\n",
    "        labels = labels.to(avDev)\n",
    "         \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "         \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "         \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)#\n",
    "         \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "         \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "         \n",
    "        iter += 1\n",
    "         \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                images = images.view(-1, 3*32*32).to(avDev)\n",
    "                 \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                 \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                 \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                 \n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum().float()\n",
    "             \n",
    "            accuracy = 100. * correct / total\n",
    "             \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the  train images: 53 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.to(avDev)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images = images.view(-1, 3*32*32).to(avDev)\n",
    "        labels = labels.to(avDev)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the  train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3072])\n"
     ]
    }
   ],
   "source": [
    "print(images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
